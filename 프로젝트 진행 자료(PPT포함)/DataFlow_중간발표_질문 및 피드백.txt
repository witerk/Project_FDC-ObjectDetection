밸리데이션 보다 테스트에 데이터 분포를 더 많이 하자
이미지 잘라서 결함을 직접적으로 넣어보자 -> 이거 우리가 함ㅋ
크롭 잘라서 넣어보자! (리사이징 -> 모델에 들어갈 수 있게 똑같은 크기로 늘려서)
모델이 인식할 수 있는 최소한의 이미지 크기 실험해보기(해상도 어디까지 버티는지)
회사에서 못 쓰는 모델(라이센스 문제)도 있음
모델 -> 트랜스퍼 러닝에 대해 이해하고 하기(스탠포드 CS231강의 참고)


"트랜스퍼 러닝(Transfer Learning)"은 머신 러닝과 딥러닝에서 사용되는 중요한 기술 중 하나입니다. 트랜스퍼 러닝은 하나의 작업에서 학습한 모델의 지식을 다른 관련 작업에 활용하여 학습 성능을 향상시키는 방법입니다. 이는 데이터가 제한적인 경우, 계산 리소스가 부족한 경우, 또는 새로운 작업을 위해 처음부터 모델을 학습시키기 어려운 경우에 유용합니다.

트랜스퍼 러닝은 크게 두 가지 방식으로 사용될 수 있습니다:

미세 조정 (Fine-tuning):
이전에 학습한 모델을 새로운 작업에 맞게 조정하여 사용하는 방식입니다. 미세 조정은 기존 모델의 일부 층을 동결시키고 새로운 작업에 대해 해당 층의 가중치만 업데이트하는 방식으로 이루어집니다. 이를 통해 새로운 작업에 맞게 모델을 세밀하게 조정하면서도 이전에 학습한 지식을 유지할 수 있습니다.

특징 추출 (Feature Extraction):
이전에 학습한 모델의 일부 층을 특징 추출기로 사용하는 방식입니다. 기존 모델의 일부 층은 동결시키고, 나머지 층은 새로운 작업에 맞게 재학습하지 않고 특징 추출에 사용합니다. 이렇게 추출된 특징을 새로운 작업에 맞는 분류기 등에 입력으로 사용하여 새로운 작업을 수행합니다.

트랜스퍼 러닝은 일반적으로 학습 데이터가 적거나 유사한 도메인의 작업에서 유용합니다. 미리 학습된 모델은 이미지 분류, 객체 감지, 언어 모델링, 자연어 처리 등 다양한 작업에 활용될 수 있으며, 특히 딥러닝의 발전과 함께 중요성이 더욱 부각되고 있습니다.


========================================

모델 적용 방식이 단순함
여러개 테스트 해보기
80은 실제에서 쓰기에 좀 약함....
90이상은 나와라
잘 나오게 하기위한 과정! 그걸 찾아라!
일반적인 전처리가 아니라 좀 기발한 거
논문같은거 찾으면, 리서치의 영역! (우리가 한 번 모방해봤는데 나아졌다~ 이런 스토리 라인)

-취업을 하기엔 프로젝트 자체의 깊이가 부족함
-데이터양이 적고, 분석 깊이가 부족하다

트/밸/테 먼저 나눈기
결함 크롭
이미지합성
새로운 모델 찾기
바운딩박스 어케 칠지 고민좀
로보 결제?

=============================================

<질문1>
원본 데이터의 양은 늘릴 수 없는 상황입니다. train(학습)데이터는 증식을 통해 늘리지만, vaildation(1차검증)과 test(2차검증)셋은 증식이 불가한 걸로 알고 있습니다. 그런데 이때 검증용셋 안에서 데이터를 증식시켜도 되는지 알고 싶습니다.
ex) test셋 안에 9장의 정상 이미지와 50장의 결함 이미지가 있습니다. 이때 정상 반도체 이미지를 증식하여(회전, 색상변환 등) 50장 정도로 만들고, 결함 이미지를 증식하여(회전, 색상변환, 이미지합성 등) 200장 정도로 만들어, 총 59장->150장의 test셋을 완성해도 괜찮은지 궁금합니다.
검증용 셋은 증식하면 안된다고 알고 있지만, 학습용 셋과 섞이지 않은 이미지로, 검증용 셋 내에서만 증식을 시행하면 검증이 여러차례 이루어질 뿐 모델 성능에는 크게 차이가 나지 않을거라는 생각에 질문 드렸습니다.

=============================================

<질문2>
반도체 결함 탐지 모델을 만들 때 필요한 적정 데이터 수가 10~20만장 정도라고 하셨는데, 저희는 데이터가 300여장 밖에 없는 상황입니다. 그래서 가능한 최대한 데이터를 증식하고자 하는데, 이때 데이터를 10~20만장까지 늘리는 게 모델 성능에 큰 영향이 없는지 궁금합니다. 
300여장의 데이터를 십만장 단위로 늘리는 것이 불가능한 일은 아니지만, 원본이 지나치게 적은 상황에서 너무 큰 규모로 늘리는 게 아닐지 하는 생각이 들어 여쭙니다.

-많다고 좋은 건 아님
-검증 때 문제가 없다면ok (과적합 문제같은거 없으면)
-학습시간 관점도 꼭 고려해야 함
-목표관점에 따라 좀 다름 -> 성능이 가장 중요하고 시간이나 리소스는 크게 상관 없다! -> 무거운 모델 써서 정확도 올리기
-현실에서 사진이 회전돼서 들어가는 경우는 없을 거 같다

다른 샘플로 학습시킨 모델을 가지고 와 반도체에 적용
이미지 수가 적어도 효율적으로 활용할 수 있는 방법
반도체 공장의 정형화된 이미지를 학습할 수 있도록 한 번 더 학습시켜주고
그러면 꽤 쓸모있는 모델이 나올 수도

앞부분은 그대로 쓰고(가중치 부분 수정 안 되게) 뒷부분(분류기 부분)만 수정하기
(ex. 출력층 개수를 줄인다거나, 분류문제인지 회귀문제인지 판단하던가)

이대로 훈련하면 앞부분이 고정됐기 때문에 뒷부분만 학습됨 (ex. 레이어가 100개면 30개만 학습시키는 등 일부만 학습)
이후에 고정 풀면 앞부분도 학습됨
고정 풀기 전후 성능 비교해보기

<전이학습 vs 파인튜닝>
-전이학습: 다른 데서 학습한 모델의 일부 혹은 전체를 사용하는 거(사전학습)
-파인튜닝: 전이학습의 한 형태/ 기존 모델의 가중치를 일부만 고정하고 나머지는 다시 학습시킴, 일부 레이어를 변경하거나, 출력층 개수를 조정하는 등 수정/ 일반적으로 적은 양의 데이터에서 유효+과적합 방지

=============================================

<질문3>
약간 번외 질문이지만, 회사에서 사용하는 GPU의 성능이 궁금합니다. 일반 개인 컴퓨터와 같다고 생각해야 할지, 아니면 모델용으로 훨씬 좋은 성능의 GPU를 사용하는지 알고 싶습니다.
이번에 딥러닝 모델을 돌릴 때 GPU메모리 부족으로 런타임 에러가 발생하는 경우가 많았는데, 그럼 이 모델들은 실제 현장에서 사용이 어려운건지(실 활용보단 학술적인 의미로 존재하는 모델들인지), 혹은 회사에서 사용하는 다른 방법이 있는지 궁금합니다.

-회사에 따라, 목적에 따라 다름
-큰 회사는 당연히 gpu성능도 좋을 거고, 해당 비용을 감당할 정도가 될 것임
(ex. cctv회사에서 무거운 모델은 필요x 대신 실시간 탐지가 용이한 모델이 더 좋을 것)

=============================================

<질문4>
여러 모델들을 활용해보려고하는데 현업에서는 어떤 기준으로 사용할 모델을 선정하는지 궁금합니다.

-검출을 얼마나 잘 해내느냐 (성능지표가 기준치 도달 하느냐/ 추론+학습시간)
	ㄴ하드웨어에 따라 요구되는 성능
-욜로도 무거운 편임 (7~80메가 정도 나올 것)
	ㄴ성능에 한계가 있음 -> 정확도에 중점을 둔 다른 모델만큼은 안 나옴
	ㄴ욜로 가지고 앙상블 해보기 (모델 구조 바꾸기)
-모델 경량화 (ex. 증류-distilation)
	ㄴex. 선생님모델(원본)의 예측 결과를 보고 학생모델(요구되는 사이즈에 맞는 작은 모델)이 답을 예측
-사용자가 gpu를 사용해 예측을 하게 하는 순간, 돈이 엄청 듬. 그래서 딥러닝 보단 머신러닝 많이 사용

-모델 사이즈, 추론 시간, 성능(정확도) 등이 주요 비교 특성
-최신 모델들을 많이 씀(그 중 큰 회사 게 좋음)
-인기있는 모델 -> 이것도 모델 선정 이유가 될 수 있음(다운로드 수가 가장 많다던가)
-환경적 제약 때문에 욜로를 선택했다~ (gpu성능 등 실험해 볼 수 있는 모델 중에 골랐다)

+train/val/test 비율을 좀 크게 가지고 갈 거 같다(ex. 6:4)
+발표 때 일부러 빈틈을 만들고 질문 유도 -> 설명(더 설명하고 싶은 이야기를 자세히 하게)
+큰 회사들은 무거운 모델 쓸 여력이 되니까, 정확도가 더 높은ㅇㅇ모델을 썼다~ (발표 때 미리 설명하고 들어가기)

=============================================

<질문5>
저희 조가 전처리 했었던 부분들이 1.클래스 재정의, 2.바운딩 박스 재조정, 3.데이터 증식, 세가지 였는데요. 피드백 주신 걸 듣고 이해한 것은 1.클래스 재정의는 의미가 없다고 해석을 하였는데 그럼 전처리는 2.바운딩 박스 재조정, 3.데이터 증식 이 두가지로 충분할지, 이 두 가지 방식 외에 조언해주실만한 또다른 전처리 방향도 궁금합니다.

=============================================

<질문6>
train, validation, test 로 나눈 데이터셋중 test 의 데이터 비율이 너무 적다라고 판단되어서 test 데이터 양을 증식해도 된다면 증식할 예정이에요. test 검증 때 모델 결과를 실제와 똑같이 뽑고싶은데 불량품 이미지와 양품 이미지의 비율을 얼마나 둬야할지 감이 잡히지 않아 비율에 대해 질문 드립니다.



